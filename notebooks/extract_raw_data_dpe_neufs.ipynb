{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf10ab40-278b-4733-85f1-078ab6868d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import concat_ws, col, lower, regexp_replace\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName('dpe_existants_rawdata_dl_job') \\\n",
    "    .master('spark://spark-master:7077') \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    "    .config('spark.ui.port', '4041') \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .config(\"spark.executor.memoryOverhead\", \"512m\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37d70dc4-f0e5-4380-8192-fb9e1e50a377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call 1 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=102500%2C915353\n",
      "Call 2 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=105000%2C819758\n",
      "Call 3 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=107500%2C965840\n",
      "Call 4 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=110000%2C377127\n",
      "Call 5 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=112500%2C969784\n",
      "Call 6 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=115213%2C145500\n",
      "Call 7 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=118546%2C688154\n",
      "Call 8 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=121880%2C409813\n",
      "Call 9 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=125213%2C853168\n",
      "Call 10 completed. Next URL: https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=128546%2C779935\n",
      "Reached maximum number of API calls. Stopping fetch.\n",
      "Number of records fetched: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 14:32:54 WARN TaskSetManager: Stage 18 contains a task of very large size (3831 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/30 14:33:18 WARN TaskSetManager: Stage 24 contains a task of very large size (3831 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "# Imports pour Spark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "# Import pour les requêtes HTTP\n",
    "import requests\n",
    "\n",
    "# Set up the logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName('dpe_existants_rawdata_dl_job') \\\n",
    ".master('spark://spark-master:7077') \\\n",
    ".config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\") \\\n",
    ".config('spark.ui.port', '4041') \\\n",
    ".getOrCreate()\n",
    "\n",
    "def fetch_from_api():\n",
    "        url = 'https://data.ademe.fr/data-fair/api/v1/datasets/dpe-v2-logements-neufs/lines?size=10000&after=100000%2C938474'\n",
    "        \n",
    "        all_results = []\n",
    "        max_calls = 10  # Number of API calls to make\n",
    "        call_count = 0  # Counter for the number of API calls\n",
    "        # Loop to handle pagination\n",
    "        while url and call_count < max_calls:\n",
    "        # Fetch the JSON data from the URL\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                try:\n",
    "                    # Parse the JSON data\n",
    "                    data = response.json()\n",
    "                    \n",
    "                    # Append the results to the all_results list\n",
    "                    all_results.extend(data['results'])\n",
    "                    \n",
    "                    # Update the URL to the next page\n",
    "                    url = data.get('next')\n",
    "                    call_count += 1\n",
    "                    print(f\"Call {call_count} completed. Next URL: {url}\")\n",
    "                    \n",
    "                    # Check if we have made 10 API calls\n",
    "                    if call_count >= max_calls:\n",
    "                        print(\"Reached maximum number of API calls. Stopping fetch.\")\n",
    "                        break\n",
    "\n",
    "                except ValueError as e:\n",
    "                    logger.error(f\"Error parsing JSON: {e}\")\n",
    "                    break\n",
    "            else:\n",
    "                logger.error(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "                logger.error(f\"Response content: {response.text}\")\n",
    "                break\n",
    "        \n",
    "        return all_results\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Conso_chauffage_dépensier_é_finale\", StringType(), True),\n",
    "    StructField(\"Emission_GES_ECS\", StringType(), True),\n",
    "    StructField(\"Type_énergie_n°1\", StringType(), True),\n",
    "    StructField(\"Type_énergie_n°2\", StringType(), True),\n",
    "    StructField(\"Nom__commune_(BAN)\", StringType(), True),\n",
    "    StructField(\"Coût_ECS_énergie_n°2\", StringType(), True),\n",
    "    StructField(\"Emission_GES_chauffage\", StringType(), True),\n",
    "    StructField(\"Date_réception_DPE\", StringType(), True),\n",
    "    StructField(\"Coût_ECS_énergie_n°1\", StringType(), True),\n",
    "    StructField(\"Coût_total_5_usages\", StringType(), True),\n",
    "    StructField(\"Conso_ECS_é_finale\", StringType(), True),\n",
    "    StructField(\"Emission_GES_5_usages\", StringType(), True),\n",
    "    StructField(\"Code_postal_(BAN)\", StringType(), True),\n",
    "    StructField(\"Conso_éclairage_é_finale\", StringType(), True),\n",
    "    StructField(\"Coût_refroidissement_dépensier\", StringType(), True),\n",
    "    StructField(\"Coordonnée_cartographique_X_(BAN)\", StringType(), True),\n",
    "    StructField(\"Date_fin_validité_DPE\", StringType(), True),\n",
    "    StructField(\"Nombre_niveau_logement\", StringType(), True),\n",
    "    StructField(\"Emission_GES_refroidissement_dépensier\", StringType(), True),\n",
    "    StructField(\"Type_bâtiment\", StringType(), True),\n",
    "    StructField(\"Conso_5_usages_par_m²_é_primaire\", StringType(), True),\n",
    "    StructField(\"Coût_refroidissement\", StringType(), True),\n",
    "    StructField(\"Ubat_W/m²_K\", StringType(), True),\n",
    "    StructField(\"Coût_ECS_dépensier\", StringType(), True),\n",
    "    StructField(\"Coût_chauffage\", StringType(), True),\n",
    "    StructField(\"Emission_GES_auxiliaires\", StringType(), True),\n",
    "    StructField(\"Emission_GES_5_usages_par_m²\", StringType(), True),\n",
    "    StructField(\"Emission_GES_éclairage\", StringType(), True),\n",
    "    StructField(\"_geopoint\", StringType(), True),\n",
    "    StructField(\"Conso_ECS_dépensier_é_primaire\", StringType(), True),\n",
    "    StructField(\"Conso_refroidissement_dépensier_é_finale\", StringType(), True),\n",
    "    StructField(\"Conso_ECS_dépensier_é_finale\", StringType(), True),\n",
    "    StructField(\"Adresse_(BAN)\", StringType(), True),\n",
    "    StructField(\"Version_DPE\", StringType(), True),\n",
    "    StructField(\"Date_visite_diagnostiqueur\", StringType(), True),\n",
    "    StructField(\"Coût_ECS\", StringType(), True),\n",
    "    StructField(\"Nombre_niveau_immeuble\", StringType(), True),\n",
    "    StructField(\"Surface_habitable_immeuble\", StringType(), True),\n",
    "    StructField(\"Coût_éclairage\", StringType(), True),\n",
    "    StructField(\"Date_établissement_DPE\", StringType(), True),\n",
    "    StructField(\"Qualité_isolation_enveloppe\", StringType(), True),\n",
    "    StructField(\"N°_voie_(BAN)\", StringType(), True),\n",
    "    StructField(\"Emission_GES_chauffage_dépensier\", StringType(), True),\n",
    "    StructField(\"N°DPE\", StringType(), True),\n",
    "    StructField(\"Conso_refroidissement_é_finale\", StringType(), True),\n",
    "    StructField(\"Conso_chauffage_é_primaire\", StringType(), True),\n",
    "    StructField(\"Appartement_non_visité_(0/1)\", StringType(), True),\n",
    "    StructField(\"Adresse_brute\", StringType(), True),\n",
    "    StructField(\"Conso_éclairage_é_primaire\", StringType(), True),\n",
    "    StructField(\"Qualité_isolation_menuiseries\", StringType(), True),\n",
    "    StructField(\"Qualité_isolation_murs\", StringType(), True),\n",
    "    StructField(\"Conso_ECS_é_primaire\", StringType(), True),\n",
    "    StructField(\"Emission_GES_5_usages_énergie_n°1\", StringType(), True),\n",
    "    StructField(\"Emission_GES_5_usages_énergie_n°2\", StringType(), True),\n",
    "    StructField(\"Etiquette_GES\", StringType(), True),\n",
    "    StructField(\"Conso_5_usages_é_finale_énergie_n°1\", StringType(), True),\n",
    "    StructField(\"Statut_géocodage\", StringType(), True),\n",
    "    StructField(\"Conso_auxiliaires_é_primaire\", StringType(), True),\n",
    "    StructField(\"Nombre_appartement\", StringType(), True),\n",
    "    StructField(\"Conso_auxiliaires_é_finale\", StringType(), True),\n",
    "    StructField(\"Conso_chauffage_é_finale\", StringType(), True),\n",
    "    StructField(\"Coût_chauffage_dépensier\", StringType(), True),\n",
    "    StructField(\"Modèle_DPE\", StringType(), True),\n",
    "    StructField(\"Etiquette_DPE\", StringType(), True),\n",
    "    StructField(\"Conso_refroidissement_dépensier_é_primaire\", StringType(), True),\n",
    "    StructField(\"Nom__commune_(Brut)\", StringType(), True),\n",
    "    StructField(\"Conso_5_usages_é_finale\", StringType(), True),\n",
    "    StructField(\"N°_département_(BAN)\", StringType(), True),\n",
    "    StructField(\"Conso_refroidissement_é_primaire\", StringType(), True),\n",
    "    StructField(\"Coût_chauffage_énergie_n°1\", StringType(), True),\n",
    "    StructField(\"_i\", IntegerType(), True),\n",
    "    StructField(\"Méthode_application_DPE\", StringType(), True),\n",
    "    StructField(\"N°_région_(BAN)\", StringType(), True),\n",
    "    StructField(\"Coût_chauffage_énergie_n°2\", StringType(), True),\n",
    "    StructField(\"Qualité_isolation_plancher_bas\", StringType(), True),\n",
    "    StructField(\"Conso_5_usages/m²_é_finale\", StringType(), True),\n",
    "    StructField(\"Hauteur_sous-plafond\", StringType(), True),\n",
    "    StructField(\"Identifiant__BAN\", StringType(), True),\n",
    "    StructField(\"Surface_habitable_logement\", StringType(), True),\n",
    "    StructField(\"Code_postal_(brut)\", StringType(), True),\n",
    "    StructField(\"Coût_auxiliaires\", StringType(), True),\n",
    "    StructField(\"Coordonnée_cartographique_Y_(BAN)\", StringType(), True),\n",
    "    StructField(\"_rand\", StringType(), True),\n",
    "    StructField(\"Nom__rue_(BAN)\", StringType(), True),\n",
    "    StructField(\"Conso_chauffage_dépensier_é_primaire\", StringType(), True),\n",
    "    StructField(\"Emission_GES_ECS_dépensier\", StringType(), True),\n",
    "    StructField(\"Code_INSEE_(BAN)\", StringType(), True),\n",
    "    StructField(\"Score_BAN\", StringType(), True),\n",
    "    StructField(\"Emission_GES_refroidissement\", StringType(), True),\n",
    "    StructField(\"Conso_5_usages_é_primaire\", StringType(), True),\n",
    "    StructField(\"_score\", StringType(), True),\n",
    "    StructField(\"_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "data = fetch_from_api()\n",
    "print(\"Number of records fetched:\", len(data))\n",
    "df = spark.createDataFrame(data, schema) \n",
    "\n",
    "df = df.withColumn('Année', F.year(F.col('Date_établissement_DPE')))\n",
    "df_filtered = df.filter(F.col('Année').isin(2021, 2022, 2023))\n",
    "\n",
    "df_filtered = df_filtered.repartition('Année')\n",
    "print(df_filtered.count())\n",
    "\n",
    "df_filtered.write.mode('overwrite').partitionBy('Année').format('parquet') \\\n",
    "    .option(\"path\", \"hdfs:///hadoop/dfs/data/DPE/raw_data/dpe_logements_neufs/lot_4/\") \\\n",
    "    .saveAsTable(\"dpe_logements_neufs\")\n",
    "\n",
    "\n",
    "# Stop the SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1d62f74-3f94-4d3b-b2aa-ad43e9c8f670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87186"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b b= spark.read.parquet('hdfs:///hadoop/dfs/data/DPE/raw_data/dpe_logements_existants')\n",
    "a = spark.read.parquet('hdfs:///hadoop/dfs/data/DPE/raw_data/dpe_logements_existants/lot_1')\n",
    "a.count()\n",
    "# 87109"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
