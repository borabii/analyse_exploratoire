version: '3'

services:

  pgadmin:
    image: dpage/pgadmin4:latest
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "8082:80"
    networks:
      - my_shared_network
 # spark
  spark:
      image: docker.io/bitnami/spark:3.3
      environment:
        - SPARK_MODE=master
      ports:
        - '4040:4040'
        - '7077:7077'
      volumes:
        - ./pak:/opt/workspace
      env_file:
        - ./hadoop.env
      networks:
        - my_shared_network

  spark-worker:
    image: docker.io/bitnami/spark:3.3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_EXECUTOR_MEMORY=2G
      - SPARK_WORKER_CORES=2
    volumes:
      - ./pak:/opt/workspace
    env_file:
      - ./hadoop.env
    networks:
      - my_shared_network
  
  # jupyterlab:
  #   image: jupyter/pyspark-notebook:spark-3.3.2 
  #   container_name: jupyterlab-ML
  #   ports:
  #     - 8888:8888
  #   volumes:
  #     - ./pak:/opt/workspace 
        
  # spark-master:
  #   image: apache/spark:3.5.1
  #   container_name: spark-master
  #   ports:
  #     - "9090:8082"
  #     - "7077:7077"
  #   env_file:
  #     - ./hadoop.env
  #   networks:
  #     - my_shared_network
 
  # spark-worker:
  #   image: apache/spark:3.5.1
  #   depends_on:
  #     - spark-master
  #   environment:
  #     - SPARK_MASTER=spark://spark-master:7077
  #   ports:
  #     - 8081:8081
  #   env_file:
  #     - ./hadoop.env
  #   networks:
  #     - my_shared_network

  # spark-notebook:
  #   image: apache/spark:3.5.1
  #   container_name: spark-notebook
  #   env_file:
  #     - ./hadoop.env
  #   ports:
  #     - 9001:9001
  #   entrypoint: sh -c "rm -f /opt/spark-notebook/RUNNING_PID && /opt/spark-notebook/bin/spark-notebook"
  #   volumes:
  #     - ./notebooks:/opt/spark-notebook/notebooks
    
  #   networks:
  #     - my_shared_network
  
#hadoop
  namenode:
    image: bde2020/hadoop-namenode:1.1.0-hadoop2.8-java8
    container_name: namenode
    volumes:
      - ./data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    ports:
      - 50070:50070
    networks:
      - my_shared_network

  datanode:
    image: bde2020/hadoop-datanode:1.1.0-hadoop2.8-java8
    depends_on: 
      - namenode
    volumes:
      - ./data/datanode:/hadoop/dfs/data
    env_file:
      - ./hadoop.env
    ports:
      - 50075:50075
    networks:
      - my_shared_network
    
  hue:
    image: bde2020/hdfs-filebrowser:3.11
    ports:
      - 8088:8088
    environment:
      - NAMENODE_HOST=namenode
    networks:
      - my_shared_network
    

networks:
  my_shared_network:
    external: true